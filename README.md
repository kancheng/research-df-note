# research-df-note

- https://github.com/kancheng/kan-cs-report-in-2022/tree/main/DMSASD/final

## Details

1. https://github.com/bharat-b7/IPNet

2. https://github.com/yjn870/FSRCNN-pytorch

## Links

1. 可解释的人工智能 : https://www.jiqizhixin.com/graph/technologies/60c538c0-32a9-4415-abab-6e1c0fba4cb3


# Paper

## Survey

1. The Creation and Detection of Deepfakes: A Survey

- https://arxiv.org/abs/2004.11138

2. Deep learning for deepfakes creation and detection: A survey

- https://www.sciencedirect.com/science/article/abs/pii/S1077314222001114

3. DeepFake Creation and Detection:A Survey

- https://ieeexplore.ieee.org/document/9544522


## Detecting Deepfakes

1. Detecting Deepfakes With Self-Blended Images :

- https://openaccess.thecvf.com/content/CVPR2022/papers/Shiohara_Detecting_Deepfakes_With_Self-Blended_Images_CVPR_2022_paper.pdf

- https://github.com/mapooon/SelfBlendedImages

2. DeepFake Disrupter: The Detector of DeepFake Is My Friend

- https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.html

```
In recent years, with the advances of generative models, many powerful face manipulation systems have been developed based on Deep Neural Networks (DNNs), called DeepFakes.

If DeepFakes are not controlled timely and properly, they would become a real threat to both celebrities and ordinary people.

Precautions such as adding perturbations to the source inputs will make DeepFake results look distorted from the perspective of human eyes.

However, previous method doesn’t explore whether the disrupted images can still spoof DeepFake detectors.

This is critical for many applications where DeepFake detectors are used to discriminate between DeepFake data and real data due to the huge cost of examining a large amount of data manually.

We argue that the detectors do not share a similar perspective as human eyes, which might still be spoofed by the disrupted data. 

Besides, the existing disruption methods rely on iteration-based perturbation generation algorithms, which is time-consuming.

In this paper, we propose a novel DeepFake disruption algorithm called “DeepFake Disrupter”. 

By training a perturbation generator, we can add the human-imperceptible perturbations to source images that need to be protected without any backpropagation update.

The DeepFake results of these protected source inputs would not only look unrealistic by the human eye but also can be distinguished by DeepFake detectors easily. 

For example, experimental results show that by adding our trained perturbations, fake images generated by StarGAN [5] can result in a 10 ∼ 20% increase in F1-score evaluated by various DeepFake detectors.

```

3. Two-branch Recurrent Network for Isolating Deepfakes in Videos

- https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123520647.pdf


## CVPR

1. amusi/CVPR2022-Papers-with-Code : https://github.com/amusi/CVPR2022-Papers-with-Code

- https://github.com/amusi/daily-paper-computer-vision

2. CVPR 2022 整理 : 

- https://github.com/extreme-assistant/CVPR2022-Paper-Code-Interpretation

- https://www.cvmart.net/community/detail/6124


## ICCV

1. ID-Reveal: Identity-Aware DeepFake Video Detection

- https://openaccess.thecvf.com/content/ICCV2021/papers/Cozzolino_ID-Reveal_Identity-Aware_DeepFake_Video_Detection_ICCV_2021_paper.pdf

## ECCV

1. SeqDeepFake: Detecting and Recovering Sequential DeepFake Manipulation

- https://github.com/rshaojimmy/SeqDeepFake

- https://arxiv.org/pdf/2207.02204.pdf


# Links

## kaggle

- https://www.kaggle.com/c/deepfake-detection-challenge

## zhihu

1. Deepfake detection文章总结 : 

- https://zhuanlan.zhihu.com/p/115070797

- https://zhuanlan.zhihu.com/p/376972313

- https://zhuanlan.zhihu.com/p/378829258


